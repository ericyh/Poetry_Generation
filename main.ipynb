{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3186\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "corpus = []\n",
    "\n",
    "def read_text_file(file_path): \n",
    "    with open(file_path, 'r') as f: \n",
    "        file = f.read()\n",
    "        for line in file.split(\"\\n\"):\n",
    "            corpus.append(line)\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".txt\"): \n",
    "        file_path = f\"{file}\"\n",
    "        read_text_file(file_path) \n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5763\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    2   40    9    1  609    3\n",
      "     4]\n",
      " [   0    0    0    0    0    0    0    2   40    9    1  609    3    4\n",
      "  1921]\n",
      " [   0    0    0    0    0    0    2   40    9    1  609    3    4 1921\n",
      "   405]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  610\n",
      "     4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  610    4\n",
      "   264]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  610    4  264\n",
      "     2]\n",
      " [   0    0    0    0    0    0    0    0    0    0  610    4  264    2\n",
      "   331]\n",
      " [   0    0    0    0    0    0    0    0    0  610    4  264    2  331\n",
      "     4]\n",
      " [   0    0    0    0    0    0    0    0  610    4  264    2  331    4\n",
      "   332]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    2\n",
      "  1134]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    2 1134\n",
      "    45]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    2 1134   45\n",
      "    21]\n",
      " [   0    0    0    0    0    0    0    0    0    0    2 1134   45   21\n",
      "     6]\n",
      " [   0    0    0    0    0    0    0    0    0    2 1134   45   21    6\n",
      "    65]\n",
      " [   0    0    0    0    0    0    0    0    2 1134   45   21    6   65\n",
      "   293]\n",
      " [   0    0    0    0    0    0    0    2 1134   45   21    6   65  293\n",
      "     2]\n",
      " [   0    0    0    0    0    0    2 1134   45   21    6   65  293    2\n",
      "  1922]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0   66\n",
      "   111]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0   66  111\n",
      "    12]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   66  111   12\n",
      "   202]\n",
      " [   0    0    0    0    0    0    0    0    0    0   66  111   12  202\n",
      "    13]\n",
      " [   0    0    0    0    0    0    0    0    0   66  111   12  202   13\n",
      "    12]\n",
      " [   0    0    0    0    0    0    0    0   66  111   12  202   13   12\n",
      "  1923]\n",
      " [   0    0    0    0    0    0    0   66  111   12  202   13   12 1923\n",
      "     6]\n",
      " [   0    0    0    0    0    0   66  111   12  202   13   12 1923    6\n",
      "  1135]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  155\n",
      "   218]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  155  218\n",
      "     5]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  155  218    5\n",
      "  1924]\n",
      " [   0    0    0    0    0    0    0    0    0    0  155  218    5 1924\n",
      "    37]\n",
      " [   0    0    0    0    0    0    0    0    0  155  218    5 1924   37\n",
      "     4]\n",
      " [   0    0    0    0    0    0    0    0  155  218    5 1924   37    4\n",
      "   202]\n",
      " [   0    0    0    0    0    0    0  155  218    5 1924   37    4  202\n",
      "  1925]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    2\n",
      "   179]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    2  179\n",
      "     1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    2  179    1\n",
      "   857]\n",
      " [   0    0    0    0    0    0    0    0    0    0    2  179    1  857\n",
      "    45]\n",
      " [   0    0    0    0    0    0    0    0    0    2  179    1  857   45\n",
      "  1926]\n",
      " [   0    0    0    0    0    0    0    0    2  179    1  857   45 1926\n",
      "     2]\n",
      " [   0    0    0    0    0    0    0    2  179    1  857   45 1926    2\n",
      "  1136]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  155\n",
      "    41]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  155   41\n",
      "  1927]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  155   41 1927\n",
      "  1928]\n",
      " [   0    0    0    0    0    0    0    0    0    0  155   41 1927 1928\n",
      "     7]\n",
      " [   0    0    0    0    0    0    0    0    0  155   41 1927 1928    7\n",
      "    50]\n",
      " [   0    0    0    0    0    0    0    0  155   41 1927 1928    7   50\n",
      "  1929]\n",
      " [   0    0    0    0    0    0    0  155   41 1927 1928    7   50 1929\n",
      "     2]\n",
      " [   0    0    0    0    0    0  155   41 1927 1928    7   50 1929    2\n",
      "  1137]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0   10\n",
      "  1138]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0   10 1138\n",
      "     5]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   10 1138    5\n",
      "  1930]]\n"
     ]
    }
   ],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = \"pre\"))\n",
    "print(input_sequences[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = input_sequences[:,:-1]\n",
    "labels = input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes = total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 00:00:29.605205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-03 00:00:29.605965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-03 00:00:29.606474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-03 00:00:29.652660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-03 00:00:29.666778: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-03 00:00:29.667313: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-03 00:00:29.667811: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words, 240, input_length = max_sequence_len - 1),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
    "    tf.keras.layers.Dense(total_words, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "174/555 [========>.....................] - ETA: 7s - loss: 0.5105 - accuracy: 0.8592"
     ]
    }
   ],
   "source": [
    "history = model.fit(xs, ys, epochs = 30, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
